#!/bin/bash
set -euo pipefail
. /.functions

set_as_boolean DEBUG

set_or_default BASE_DIR "/app"
set_or_default DATA_DIR "${BASE_DIR}/data"
set_or_default DWHS_DIR "${DATA_DIR}/dw"
set_or_default LOGS_DIR "${BASE_DIR}/logs"

set_or_default ADMIN_PORT "8443"

redirect_logs "${LOGS_DIR}/config-post.log"

set_or_default DEPLOYED_MARKER ".deployed"

# By default, wait up to 900 seconds if not told otherwise
set_or_default INIT_POLL_SLEEP
[[ "${INIT_POLL_SLEEP}" =~ ^[1-9][0-9]*$ ]] || INIT_POLL_SLEEP=2
set_or_default INIT_MAX_WAIT
[[ "${INIT_MAX_WAIT}" =~ ^[1-9][0-9]*$ ]] || INIT_MAX_WAIT=900

set_or_default ADMIN_URL "https://localhost:${ADMIN_PORT}/pentaho/"
poll_url "${ADMIN_URL}" "${INIT_MAX_WAIT}" "${INIT_POLL_SLEEP}" || fail "Cannot continue configuration if Pentaho is not online"

# First things first: go through every config directory in the DW reports areas,
# and render all the templates. THEN, add all the connections and schemas, one by one
JOBS=()
while read KJB ; do
	JOB="${KJB%/*}"
	KJB="${KJB##*/}"

	# If this deployment shouldn't be updated, we skip it
	is_file "${JOB}/${DEPLOYED_MARKER}" || continue

	# Clear the marker, regardless of the result... if it succeeds, we're OK,
	# but if it fails, we shouldn't re-attempt it, either, b/c it's clearly broken
	rm -f "${JOB}/${DEPLOYED_MARKER}" &>/dev/null || true

	# Do the deed!
	if install-kjb-dependencies "${JOB}" ; then
		# All is well, add the KJB to the run queue
		JOB+="/${KJB}"
		doing "\tAdding a PDI bootup job: [${JOB}]"
		JOBS+=("${JOB}")
		continue
	fi

	# Report the issue, keep moving
	err "Failed to install the dependencies for the KJB job at [${JOB}] (${KJB})"
done < <(find "${DWHS_DIR}" -mindepth 2 -maxdepth 2 -type f -iname 'j_*.kjb' | sort)
JOBS_COUNT=${#JOBS[@]}

if [ ${JOBS_COUNT} -gt 0 ] ; then
	# Before we can run the dataminer first time, we MUST wait for
	# ArkCase to come up ... if it doesn't, we're screwed
	set_or_default CORE_URL "https://core:8443/arkcase/"
	say "Found ${JOBS_COUNT} dataminers:"
	for J in "${JOBS[@]}" ; do
		say "\t${J}"
	done
	running "Launching the background poller for [${CORE_URL}]..."
	coproc { poll_url "${CORE_URL}" "${INIT_MAX_WAIT}" "${INIT_POLL_SLEEP}" ; }
else
	warn "No jobs found, will not wait for ArkCase to boot up"
fi

# Install the reports ... this *has* to happen last b/c the PDI stuff
# won't install cleanly if the rest of its dependencies aren't already covered
#
# We also run this in parallel with waiting for ArkCase to come up, b/c
# we try to be efficient with time :D
doing "Deploying reports"
install-reports
ok "Reports deployed"

# If we have to rejoin with the ArkCase poller, do so...
if [ -v COPROC_PID ] ; then
	waiting "Joining the background poller for [${CORE_URL}]..."
	wait ${COPROC_PID} || fail "Failed to wait for ArkCase to be online"
fi

# Leave this here ... if there are no jobs, nothing will happen...
for JOB in "${JOBS[@]}" ; do
	JOB_LOG="${JOB%.*}.log"
	doing "Launching the first-time PDI job [${JOB}]..."
	if run-kjb "${JOB}" < /dev/null &> "${JOB_LOG}" ; then
		ok "Job completed successfully"
	else
		err "Errors detected, please review the log at [${JOB_LOG}]"
	fi
done

ok "Post-configuration completed"
