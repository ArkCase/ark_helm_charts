#!/bin/bash
SCRIPT="$(/usr/bin/readlink -f "${BASH_ARGV0:-${BASH_SOURCE:-${0}}}")"
BASEDIR="$(/usr/bin/dirname "${SCRIPT}")"

set -euo pipefail

[ -v DISABLE_CLONE ] || DISABLE_CLONE=""
case "${DISABLE_CLONE,,}" in
	true | t | yes | y ) DISABLE_CLONE="true" ;;
	* ) DISABLE_CLONE="false" ;;
esac
export DISABLE_CLONE

POD_POLL_WAIT="10"
POD_REBOOT_WAIT="60"
POD_REBOOT_TIMEOUT="$(( POD_REBOOT_WAIT * 15 ))"

timestamp()
{
	/usr/bin/date -Ins
}

say()
{
	echo -e "$(timestamp): ${@}"
}

ok()
{
	say "âœ… ${@}"
}

warn()
{
	say "âš ï¸ ${@}"
}

err()
{
	say "âŒ ${@}" 1>&2
}

fail()
{
	err "${@}"
	exit ${EXIT_CODE:-1}
}

is_valid_name()
{
	local NAME="${1}"
	[[ "${NAME}" =~ ^[a-z0-9]([a-z0-9-]*[a-z0-9])?$ ]] || return ${?}
	return 0
}

execute()
{
	#
	# Show the command about to be executed
	#
	say "${@@Q}"
	if "${DISABLE_CLONE}" ; then
		warn "Cloning disabled: skipping the command execution"
		return 0
	fi

	#
	# Proceed with the execution
	#
	( exec "${@}" )
	return ${?}
}

get_deployment_status()
{
	local STATUS=""

	# Have to split this or our logic won't work
	STATUS="$("${HELM}" status "${RELEASE}" --namespace "${NAMESPACE}" -o json)" || return ${?}

	# Can be one of: unknown, deployed, uninstalled,
	# superseded, failed, uninstalling, pending-install,
	# pending-upgrade or pending-rollback
	local RESULT=""
	RESULT="$("${JQ}" -r '.info.status' <<< "${STATUS}")" || return ${?}
	echo -n "${RESULT}"
	return 0
}

should_install()
{
	local STATUS=""
	STATUS="$(get_deployment_status)"
	case "${STATUS,,}" in
		deployed ) return 1 ;;
		* ) return 0 ;;
	esac
}

should_uninstall()
{
	local STATUS=""
	STATUS="$(get_deployment_status)"
	case "${STATUS,,}" in
		uninstalled ) return 1 ;;
		* ) return 0 ;;
	esac
}

is_namespace_exists()
{
	local NAMESPACE="${1}"
	execute "${KUBECTL}" get namespace "${NAMESPACE}" &>/dev/null || return ${?}
	return 0
}

is_pod_waitable()
{
	local POD="${1}"

	local JSON=""
	JSON="$("${KUBECTL}" get pod --namespace "${NAMESPACE}" "${POD}" -o json)" || return 1

	local TS=""
	TS="$("${JQ}" -r ".metadata.deletionTimestamp" <<< "${JSON}")" || return 1

	# If the deletion timestamp is set, the pod is going down
	[ -n "${TS}" ] && return 1

	# TODO: Anything else we need to look at in the JSON?

	return 0
}

deploy_chart()
{
	should_install || return 0
	execute "${HELM}" install \
		"${RELEASE}" arkcase/pvc-tool \
		--namespace "${NAMESPACE}" \
		--set mode=clone || fail "Unable to deploy the chart"
}

wait_until_pod_exists()
{
	local POD="${1}"
	local NEXT_WAIT=${POD_REBOOT_WAIT}
	local FIRST="true"
	local START="$(/usr/bin/date +%s)"
	local END="$(( START + POD_REBOOT_TIMEOUT ))"
	while true; do
		if ! "${FIRST}" ; then
			# Apply the polling wait ...
			say "ðŸ’¤ Sleeping for ${NEXT_WAIT} before checking for its existence again..."
			/usr/bin/sleep ${NEXT_WAIT} || return ${?}
		fi

		"${KUBECTL}" get pod \
			--namespace "${NAMESPACE}" "${POD}" &>/dev/null && return 0

		"${FIRST}" && warn "The pod ${NAMESPACE}/${POD} doesn't exist yet..."
		FIRST="false"

		local NOW="$(/usr/bin/date +%s)"
		[ $(( NOW - START )) -ge ${POD_REBOOT_TIMEOUT} ] && break
		[ $(( NOW + NEXT_WAIT )) -lt ${END} ] || NEXT_WAIT=$(( END - NOW ))
	done

	# Should never happen, but if it does...
	err "The pod didn't come up in ${POD_REBOOT_TIMEOUT} seconds, can't wait anymore"
	return 1
}

wait_until_pod_is_initialized()
{
	local POD="${1}"

	local OUT=""

	local RC=${?}
	return ${RC}

	local NEXT_WAIT=${POD_REBOOT_WAIT}
	local FIRST="true"
	local START="$(/usr/bin/date +%s)"
	local END="$(( START + POD_REBOOT_TIMEOUT ))"
	while true; do
		"${FIRST}" || say "ðŸ’¤ Waiting for ${NEXT_WAIT} seconds before checking for its status again..."
		OUT="$("${KUBECTL}" wait pod \
			--namespace "${NAMESPACE}" "${POD}" \
			--for condition=Initialized=true \
			--timeout="${NEXT_WAIT}s" 2>&1)" && return 0

		# Edge case: the pod is killed while we were waiting
		is_pod_waitable "${POD}" || return ${?}

		"${FIRST}" && warn "The pod ${NAMESPACE}/${POD} isn't initialized yet..."
		FIRST="false"

		local NOW="$(/usr/bin/date +%s)"
		[ $(( NOW - START )) -ge ${POD_REBOOT_TIMEOUT} ] && break
		[ $(( NOW + NEXT_WAIT )) -lt ${END} ] || NEXT_WAIT=$(( END - NOW ))
	done

	# Should never happen, but if it does...
	err "Failed to wait for pod initialization (rc=${RC})\n${OUT}"
	return 1
}

get_pod_status()
{
	local POD="${1}"
	local CONTAINER="${2}"
	local STATUS="${3}"

	local OUT=""
	local RC=0
	OUT="$("${KUBECTL}" get pod --namespace "${NAMESPACE}" "${POD}" -o jsonpath="{.status.containerStatuses[?(@.name==\"${CONTAINER}\")].${STATUS}}" 2>&1)" || RC=${?}
	if [ ${RC} -ne 0 ] ; then
		err "Failed to query the pod's container ${STATUS} status (rc=${RC})\n${OUT}"
		return ${RC}
	fi

	echo -n "${OUT}"
	return 0
}

is_job_complete()
{
	local POD="${1}"

	local STATUS=""
	STATUS="$(get_pod_status "${POD}" "clone" "ready")" || return ${?}

	"${STATUS}" && return 0
	return 1
}

wait_until_pod_is_running()
{
	local POD="${1}"
	local NEXT_WAIT=${POD_REBOOT_WAIT}
	local FIRST="true"
	local START="$(/usr/bin/date +%s)"
	local END="$(( START + POD_REBOOT_TIMEOUT ))"
	while true; do
		if ! "${FIRST}" ; then
			# Apply the polling wait ...
			say "ðŸ’¤ Sleeping for ${NEXT_WAIT} before checking for status again..."
			/usr/bin/sleep ${NEXT_WAIT} || return ${?}
		fi

		wait_until_pod_is_initialized "${POD}" || return ${?}

		local STATUS=""
		STATUS="$(get_pod_status "${POD}" "clone" "started")" || return ${?}

		# Status is expected to be either "true" or "false"
		"${STATUS}" && return 0

		"${FIRST}" && warn "The pod ${NAMESPACE}/${POD} isn't running yet..."
		FIRST="false"

		local NOW="$(/usr/bin/date +%s)"
		[ $(( NOW - START )) -ge ${POD_REBOOT_TIMEOUT} ] && break
		[ $(( NOW + NEXT_WAIT )) -lt ${END} ] || NEXT_WAIT=$(( END - NOW ))
	done

	# Should never happen, but if it does...
	err "The pod didn't start running in ${POD_REBOOT_TIMEOUT} seconds, can't wait anymore"
	return 1
}

wait_until_job_completes()
{
	local POD="${1}"

	local NEXT_WAIT=${POD_POLL_WAIT}
	local FIRST="true"
	while true; do
		"${FIRST}" || say "ðŸ’¤ Waiting for ${NEXT_WAIT} seconds before checking for its status again..."
		OUT="$("${KUBECTL}" wait pod \
			--namespace "${NAMESPACE}" "${POD}" \
			--for condition=Ready=true \
			--timeout="${NEXT_WAIT}s" 2>&1)" && return 0

		# Edge case: the pod is killed while we were waiting
		is_pod_waitable "${POD}" || return ${?}

		"${FIRST}" && warn "The job at ${NAMESPACE}/${POD} isn't finished yet, maybe follow it with kubectl logs?"
		FIRST="false"
	done

	# Should never happen, but if it does...
	err "Failed to wait for the job to complete (rc=${RC})\n${OUT}"
	return 1
}

track_logs()
{
	local POD="${1}"
	"${KUBECTL}" logs \
		--namespace "${NAMESPACE}" \
		--tail=1000 \
		--ignore-errors \
		--follow "${POD}"
	return ${?}
}

get_pod_phase()
{
	local POD="${1}"

	local OUT=""
	OUT="$("${KUBECTL}" get pod --namespace "${NAMESPACE}" "${POD}" -o jsonpath='{ .status.phase }' 2>&1)"

	local RC=${?}
	[ ${RC} -eq 0 ] && echo -n "${OUT}"
	return ${RC}
}

get_copy_result()
{
	local POD="${RELEASE}-0"

	local POD_STATUS=""
	while true; do
		# Step 1: wait until the pod exists
		wait_until_pod_exists "${POD}" || fail "The pod did not come online"

		if ! is_job_complete "${POD}" ; then
			# Step 2: wait until the pod is running
			ok "The pod ${NAMESPACE}/${POD} exists! Waiting for it to be Ready"
			wait_until_pod_is_running "${POD}" || fail "The pod never reached the running state"

			# Step 3: Track the logs, so the user can see what's going on
			ok "The pod ${NAMESPACE}/${POD} is running!"

			# Tracking the logs no longer works b/c the pod will never exit...b/c we're
			# using a statefulset so it will restart our pod for us in the event that
			# it crashes on us. This way, the copy will continue automagically until
			# it's either completed, or found to be irrevocably failed...
			# say "ðŸ‘€ Tracking the logs for ${NAMESPACE}/${POD}"
			# track_logs "${POD}"

			# We have to wait until the pod enters the Ready state. If it dies on us,
			# then we have to start all over again
			if ! wait_until_job_completes "${POD}" ; then
				err "The pod may have crashed, restarting the monitoring loop"
				continue
			fi

			ok "The pod ${NAMESPACE}/${POD} appears to have completed its work"
		else
			ok "The pod ${NAMESPACE}/${POD} already completed its work"
		fi

		# Step 4: Pod has exited (or somesuch)...get its termination status
		local RESULT=""
		RESULT="$("${KUBECTL}" exec "${POD}" /usr/bin/cat /.pod.result 2>&1)" && return ${RESULT}

		# Something's off ... pod exited, but we can't get the status ...
		err "Failed to retrieve the pod status ... will try again (rc=${RC}):\n${RESULT}"
	done
}

undeploy_chart()
{
	should_uninstall || return 0
	execute "${HELM}" uninstall \
		"${RELEASE}" \
		--namespace "${NAMESPACE}" \
		--wait \
		--timeout=30m \
		--cascade foreground || fail "Unable to undeploy the chart"
}

usage()
{
	echo -e "usage: ${BASH_SOURCE:-${0}} [namespace] release" 1>&2
	exit 1
}

[ ${#} -ge 1 ] && [ ${#} -le 2 ] || usage

HELM="$(type -P helm)" || fail "Could not find helm in the path"
JQ="$(type -P jq)" || fail "Could not find jq in the path"
KUBECTL="$(type -P kubectl)" || fail "Could not find kubectl in the path"

if [ ${#} -eq 1 ] ; then
    NAMESPACE="$("${KUBECTL}" config view --minify -o jsonpath="{..namespace}")"
    [ -n "${NAMESPACE}" ] || NAMESPACE="${POD_NAMESPACE:-default}"
else
    NAMESPACE="${1}"
    shift
fi
is_valid_name "${NAMESPACE}" || fail "Invalid namespace name [${NAMESPACE}]"

RELEASE="${1}"
is_valid_name "${RELEASE}" || fail "Invalid release name [${RELEASE}]"

# If the target namespace doesn't exist, by extension the environment doesn't exist
if ! is_namespace_exists "${NAMESPACE}" ; then
    say "The namespace ${NAMESPACE} does not exist, so nothing to remove"
    exit 0
fi

say "ðŸ‘‰ Deploying the chart to do the volume cloning..."
deploy_chart || fail "Couldn't deploy the chart to do the volume cloning"
ok "Chart deployed!"

say "ðŸ‘‰ Run the file copy"
get_copy_result || fail "The file copy seems to have failed, please review the full logs for more information"
ok "Copy complete!"

say "ðŸ‘‰ Removing the chart to release the volumes..."
undeploy_chart || fail "Couldn't un-deploy the chart"
ok "Undeployment completed!"
