#!/bin/bash

timestamp() {
	/usr/bin/date -Ins -u
}

say() {
	echo -e "$(timestamp): ${@}"
}

err() {
	say "ERROR: ${@}" 1>&2
}

fail() {
	say "${@}"
	exit ${EXIT_CODE:-1}
}

cleanup() {
	[ -v WORK_DIR ] && rm -rf "${WORK_DIR}" &>/dev/null
}

list_configs_with_cores() {
	curl -L --fail -s "${SOLR_URL}/admin/collections?action=CLUSTERSTATUS" | \
			jq -r '.cluster.collections | to_entries[] | "\(.value | .configName)/\(.key)"'  | \
			sort
	return ${PIPESTATUS[0]}
}

upload_state() {
	local SRC="${1}"
	solr zk cp "${DST}" zk:/arkcase.deployment
}

download_state() {
	local DST="${1}"
	solr zk cp zk:/arkcase.deployment "${DST}"
}

upload_config() {
	local SOURCE_DIR="${1}"
	local CONF_NAME="${2}"
	solr zk upconfig -d "${SOURCE_DIR}" -n "${CONF_NAME}"
}

download_config() {
	local CONF_NAME="${1}"
	local TARGET_DIR="${2}"
	solr zk downconfig -d "${TARGET_DIR}" -n "${CONF_NAME}"
}

get_config_sum() {
	local DIR="${1}"
	(
		cd "${DIR}" && \
		find . -type f | \
			sort | \
			tr '\n' '\0' | \
			xargs -0 cat | \
			sha256sum | \
			awk '{ print $1 }'
	)
}

trap cleanup EXIT
set -euo pipefail

[ -v BASE_DIR ] || BASE_DIR="/app"
[ -v DATA_DIR ] || DATA_DIR="${BASE_DIR}/data"
[ -v LOGS_DIR ] || LOGS_DIR="${DATA_DIR}/logs"
[ -v ZK_HOST ] || ZK_HOST="localhost:9983"

if [ -d "${LOGS_DIR}" ] ; then
	LOG_FILE="${LOGS_DIR}/deploy.log"
	exec >> >(/usr/bin/tee -a "${LOG_FILE}")
	exec 2>&1
	say "Logs redirected to [${LOG_FILE}]"
fi

# By default, wait up to 90 seconds if not told otherwise
[ -v INIT_POLL_SLEEP ] || INIT_POLL_SLEEP=2
[[ "${INIT_POLL_SLEEP}" =~ ^[1-9][0-9]*$ ]] || INIT_POLL_SLEEP=2
[ -v INIT_MAX_WAIT ] || INIT_MAX_WAIT=90
[[ "${INIT_MAX_WAIT}" =~ ^[1-9][0-9]*$ ]] || INIT_MAX_WAIT=90

[ -v SOLR_URL ] || SOLR_URL="https://localhost:8983/solr"
SOLR_URL+="/admin/info/health"

START="$(date +%s)"
say "Starting the polling cycle"
while true ; do
	/usr/bin/curl -kL --fail -m 5 "${SOLR_URL}" &>/dev/null && break
	NOW="$(date +%s)"
	[ $(( NOW - START )) -ge ${INIT_MAX_WAIT} ] && fail "Timed out waiting for the URL [${SOLR_URL}] to come up"
	# If sleep didn't succeed, it means it got signaled, which
	# Means we need to stop what we're doing and puke out
	sleep ${INIT_POLL_SLEEP} || fail "Sleep interrupted, can't continue polling"
done
say "The URL [${SOLR_URL}] responded, continuing"

# 0) Compare the incoming desired state with the existing desired state in ZK ... if it
#	matches, then we're OK and don't need to proceed.

WORK_DIR="$(mktemp -d -p "${INIT_DIR}" ".work.XXXXXXXX")"

#
# 1) Identify the names of the existing configurations, and which cores are using them
#
while IFS="/" read CONFIG CORE ; do
	VAR="__CFG_${CONFIG}"
	[ -v ${VAR} ] || eval "${VAR}=()"
	eval "${VAR}+=(${CORE@Q})"
done < <(list_configs_with_cores)

#
# 2) Identify the names of the incoming configurations, and which cores are using them
#
# 3) Compare existing configurations with incoming configurations
#		3.1) If there's no name match, add the new configuration
#		3.2) If there's a name match, then compare the contents... if they match, leave
#			it alone and move on to the next configuration
#		3.3) If there's a name match but a contents mismatch, the old config
#			must be removed and replaced with the new one, but first all cores
#			that use it must also be removed
#
# 4) Create all new configurations (they'll be consumed by the incoming collections)
#
# 5) Compare existing collections with incoming collections
#		5.1) If there's no name match, add the new collection
#		5.2) If there's a name match, then compare the config names... if they match,
#			leave it alone and move on to the next collection
#		5.3) If there's a name match, but a config name mismatch, the old
#			collection must be removed
#
# 6) Create all new collections using the named configurations, which must already exist
#	since step 4
#
# 7) Rejoice, the state is synchronized!! Make note of it in Zookeeper "somehow", to
#	accelerate the process in the future, so that it's easy to avoid the full algorithm
#	if nothing has changed
#
