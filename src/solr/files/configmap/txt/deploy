#!/bin/bash
SCRIPT="$(readlink -f "${BASH_SOURCE:-${0}}")"

timestamp() {
	/usr/bin/date -Ins -u
}

say() {
	echo -e "$(timestamp): ${@}"
}

err() {
	say "ERROR: ${@}" 1>&2
}

fail() {
	say "${@}"
	exit ${EXIT_CODE:-1}
}

cleanup() {
	[ -v WORK_DIR ] && rm -rf "${WORK_DIR}" &>/dev/null
	[ -v COPROC_PID ] && kill -TERM "${COPROC_PID}" && wait "${COPROC_PID}"
}

list_configs_with_collections() {
	curl -L --fail -s "${SOLR_URL}/admin/collections?action=CLUSTERSTATUS" | \
			jq -r '.cluster.collections | to_entries[] | "\(.value | .configName)/\(.key)"'  | \
			sort
	return ${PIPESTATUS[0]}
}

SOLR() {
	solr "${@}" 2>/dev/null
}

zk() {
	SOLR zk "${@}"
}

set_deployment() {
	local SRC="${1}"
	zk cp "${SRC}" "zk:${STATE_LOCATION}"
}

get_deployment() {
	local DST="${1}"
	zk cp "zk:${STATE_LOCATION}" "${DST}"
}

compute_desired_state() {
	local CONF_DIR="${1}"
	local CORE_LST="${2}"
	# TODO: Do something here...
	# Need to identify 
}

compare_old_state_to() {
	local NEW_STATE="${1}"

	get_deployment "${WORK_DIR}/state.old"
	diff -burN "${OLD_STATE}" "${NEW_STATE}" &>/dev/null
	return ${?}
}

add_config() {
	local SOURCE_DIR="${1}"
	local CONF_NAME="${2}"
	zk upconfig -d "${SOURCE_DIR}" -n "${CONF_NAME}"
}

get_config() {
	local CONF_NAME="${1}"
	local TARGET_DIR="${2}"
	zk downconfig -d "${TARGET_DIR}" -n "${CONF_NAME}"
}

del_collection() {
	local COLL_NAME="${1}"
	SOLR delete -c "${COLL_NAME}" 2>/dev/null
}

add_collection() {
	local COLL_NAME="${1}"
	local CONF_NAME="${2}"
	local SHARDS="${3}"
	local REPLICAS="${4}"
	SOLR create -c "${COLL_NAME}" -n "${CONF_NAME}" -shards ${SHARDS} -replicationFactor ${REPLICAS} -V
}

get_config_sum() {
	local DIR="${1}"
	(
		cd "${DIR}" && \
		find . -type f | \
			sort | \
			tr '\n' '\0' | \
			xargs -0 cat | \
			sha256sum | \
			awk '{ print $1 }'
	)
}

trap cleanup EXIT
set -euo pipefail

[ -v BASE_DIR ] || BASE_DIR="/app"
[ -v DATA_DIR ] || DATA_DIR="${BASE_DIR}/data"
[ -v LOGS_DIR ] || LOGS_DIR="${DATA_DIR}/logs"
[ -v ZK_HOST ] || ZK_HOST="localhost:9983"

if [ -d "${LOGS_DIR}" ] ; then
	LOG_FILE="${LOGS_DIR}/deploy.log"
	exec >> >(/usr/bin/tee -a "${LOG_FILE}")
	exec 2>&1
	say "Logs redirected to [${LOG_FILE}]"
fi

# By default, wait up to 90 seconds if not told otherwise
[ -v INIT_POLL_SLEEP ] || INIT_POLL_SLEEP=2
[[ "${INIT_POLL_SLEEP}" =~ ^[1-9][0-9]*$ ]] || INIT_POLL_SLEEP=2
[ -v INIT_MAX_WAIT ] || INIT_MAX_WAIT=90
[[ "${INIT_MAX_WAIT}" =~ ^[1-9][0-9]*$ ]] || INIT_MAX_WAIT=90

[ -v SOLR_URL ] || SOLR_URL="https://localhost:8983/solr"
SOLR_URL+="/admin/info/health"

START="$(date +%s)"
say "Starting the polling cycle"
while true ; do
	/usr/bin/curl -kL --fail -m 5 "${SOLR_URL}" &>/dev/null && break
	NOW="$(date +%s)"
	[ $(( NOW - START )) -ge ${INIT_MAX_WAIT} ] && fail "Timed out waiting for the URL [${SOLR_URL}] to come up"
	# If sleep didn't succeed, it means it got signaled, which
	# Means we need to stop what we're doing and puke out
	sleep ${INIT_POLL_SLEEP} || fail "Sleep interrupted, can't continue polling"
done
say "The URL [${SOLR_URL}] responded, continuing"

STATE_LOCATION="/arkcase.deployment"

#
# First things first: acquire the lock.
#
# We do it like this because there really is no need to implement a complex
# double-check-lock thing here. The only thing that matters is that only ONE of the
# nodes perform the initialization steps so we're not constantly doing it.
#
# Which node is irrelevant.
#
if [ -v CURATOR_WRAPPED ] ; then
	case "${CURATOR_WRAPPED,,}" in

		# If we're already wrapped by the curator, we do nothing b/c we hold the lock already
		true ) ;;

		# We don't hold the lock, so we try to acquire it ...
		* )	export WRAPPED_SCRIPT="${SCRIPT}" ; exec java -jar "/usr/local/bin/curator-wrapper.jar" ;;
	esac
fi

#
# Create the work directory where everything will be done
#
WORK_DIR="$(mktemp -d -p "${INIT_DIR}" ".work.XXXXXXXX")"

#
# 1) Compare the incoming desired state with the existing desired state in ZK ... if it
#	matches, then we're OK and don't need to proceed.
NEW_STATE="${WORK_DIR}/state.new"

# We only do this once, as it won't change for us...
compute_desired_state "" "" > "${NEW_STATE}"

if compare_old_state_to "${NEW_STATE}" ; then
	say "âœ… the existing state is consistent with the desired state, will not re-deploy"
	exit 0
fi

#
# 2) Identify the names of the existing configurations, and which collections are using them
#
OLD_CONF_PREFIX="__OLD_CONF_"
while IFS="/" read CONFIG COLLECTION ; do
	VAR="${OLD_CONF_PREFIX}${CONFIG}"
	if [ ! -v "${VAR}" ] ; then
		# Declare the array to hold the collections
		declare -a "${VAR}"

		# Find the config's checksum in the stored state
		SUMVAR="${OLD_CONF_PREFIX}${CONFIG}_SUM"
		IFS="/" read NAME SUM DATE < <(grep "^${CONFIG}/" "${OLD_STATE}")
		eval "${SUMVAR}=${SUM@Q}"
	fi
	eval "${VAR}+=(${COLLECTION@Q})"
done < <(list_configs_with_collections)

# At this point we have a set of arrays named __CONF_${configName} whose members are
# the names of the collections that use that configuration. That's how we'll do the
# comparisons below.

#
# 3) Identify the names of the incoming configurations, and which collections are using them
#

#
# 4) Compare existing configurations with incoming configurations
#		4.1) If there's no name match, add the new configuration
#		4.2) If there's a name match, then compare the contents... if they match, leave
#			it alone and move on to the next configuration
#		4.3) If there's a name match but a contents mismatch, the old config
#			must be removed and replaced with the new one, but first all collections
#			that use it must also be removed
#
eval "CONFIG_VARS=(\${!${OLD_CONF_PREFIX}@})"
for CV in "${CONFIG_VARS[@]}" ; do
	# Get the config's name without the prefix
	CONFIG_NAME="${CV:${#OLD_CONF_PREFIX}}"

	# Is this config part of the incoming configs?
	#	If not, add it to the nuke list, add the collections to the nuke list
	# Is this config equals to the incoming config of the same name?
	#	If so, continue
	# Add it to the nuke list, add the collections to the nuke list
done

#
# 5) Create all new configurations (they'll be consumed by the incoming collections)
#

#
# 6) Compare existing collections with incoming collections
#		6.1) If there's no name match, add the new collection
#		6.2) If there's a name match, then compare the config names... if they match,
#			leave it alone and move on to the next collection
#		6.3) If there's a name match, but a config name mismatch, the old
#			collection must be removed
#

#
# 7) Create all new collections using the named configurations, which must already exist
#	since step 5
#

#
# 8) Rejoice, the state is synchronized!! Make note of it in Zookeeper to
#	accelerate the process in the future, so that it's easy to avoid the
#	full algorithm if nothing has changed
#
set_deployment "${NEW_STATE}"
