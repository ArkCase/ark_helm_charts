#!/bin/bash

timestamp() {
	/usr/bin/date -Ins -u
}

say() {
	echo -e "$(timestamp): ${@}"
}

err() {
	say "ERROR: ${@}" 1>&2
}

fail() {
	say "${@}"
	exit ${EXIT_CODE:-1}
}

cleanup() {
	[ -v WORK_DIR ] && rm -rf "${WORK_DIR}" &>/dev/null
	[ -v COPROC_PID ] && kill -TERM "${COPROC_PID}" && wait "${COPROC_PID}"
}

list_configs_with_collections() {
	curl -L --fail -s "${SOLR_URL}/admin/collections?action=CLUSTERSTATUS" | \
			jq -r '.cluster.collections | to_entries[] | "\(.value | .configName)/\(.key)"'  | \
			sort
	return ${PIPESTATUS[0]}
}

zk() {
	solr zk "${@}" 2>/dev/null
}

upload_state() {
	local SRC="${1}"
	zk cp "${SRC}" zk:/arkcase.deployment
}

download_state() {
	local DST="${1}"
	zk cp zk:/arkcase.deployment "${DST}"
}

compute_desired_state() {
	local CONF_DIR="${1}"
	local CORE_LST="${2}"
	# TODO: Do something here...
}

compare_old_state_to() {
	local NEW_STATE="${1}"

	download_state "${WORK_DIR}/state.old"
	diff -burN "${OLD_STATE}" "${NEW_STATE}" &>/dev/null
	return ${?}
}

upload_config() {
	local SOURCE_DIR="${1}"
	local CONF_NAME="${2}"
	zk upconfig -d "${SOURCE_DIR}" -n "${CONF_NAME}"
}

download_config() {
	local CONF_NAME="${1}"
	local TARGET_DIR="${2}"
	zk downconfig -d "${TARGET_DIR}" -n "${CONF_NAME}"
}

get_config_sum() {
	local DIR="${1}"
	(
		cd "${DIR}" && \
		find . -type f | \
			sort | \
			tr '\n' '\0' | \
			xargs -0 cat | \
			sha256sum | \
			awk '{ print $1 }'
	)
}

trap cleanup EXIT
set -euo pipefail

[ -v BASE_DIR ] || BASE_DIR="/app"
[ -v DATA_DIR ] || DATA_DIR="${BASE_DIR}/data"
[ -v LOGS_DIR ] || LOGS_DIR="${DATA_DIR}/logs"
[ -v ZK_HOST ] || ZK_HOST="localhost:9983"

if [ -d "${LOGS_DIR}" ] ; then
	LOG_FILE="${LOGS_DIR}/deploy.log"
	exec >> >(/usr/bin/tee -a "${LOG_FILE}")
	exec 2>&1
	say "Logs redirected to [${LOG_FILE}]"
fi

# By default, wait up to 90 seconds if not told otherwise
[ -v INIT_POLL_SLEEP ] || INIT_POLL_SLEEP=2
[[ "${INIT_POLL_SLEEP}" =~ ^[1-9][0-9]*$ ]] || INIT_POLL_SLEEP=2
[ -v INIT_MAX_WAIT ] || INIT_MAX_WAIT=90
[[ "${INIT_MAX_WAIT}" =~ ^[1-9][0-9]*$ ]] || INIT_MAX_WAIT=90

[ -v SOLR_URL ] || SOLR_URL="https://localhost:8983/solr"
SOLR_URL+="/admin/info/health"

START="$(date +%s)"
say "Starting the polling cycle"
while true ; do
	/usr/bin/curl -kL --fail -m 5 "${SOLR_URL}" &>/dev/null && break
	NOW="$(date +%s)"
	[ $(( NOW - START )) -ge ${INIT_MAX_WAIT} ] && fail "Timed out waiting for the URL [${SOLR_URL}] to come up"
	# If sleep didn't succeed, it means it got signaled, which
	# Means we need to stop what we're doing and puke out
	sleep ${INIT_POLL_SLEEP} || fail "Sleep interrupted, can't continue polling"
done
say "The URL [${SOLR_URL}] responded, continuing"

WORK_DIR="$(mktemp -d -p "${INIT_DIR}" ".work.XXXXXXXX")"

#
# 0) Compare the incoming desired state with the existing desired state in ZK ... if it
#	matches, then we're OK and don't need to proceed.
NEW_STATE="${WORK_DIR}/state.new"

# We only do this once, as it won't change for us...
compute_desired_state "" "" > "${NEW_STATE}"

if compare_old_state_to "${NEW_STATE}" ; then
	say "✅ the existing state is consistent with the desired state, will not re-deploy"
	exit 0
fi

#
# The state didn't match ... acquire the leadership lock, and test it again
#

#
# TODO: Maybe acquire the lock through a coproc, which (once again) tells us
# via stdout that it's acquired the lock and thus we can keep going? Just remember
# to kill the coproc at exit time
#

# We have the lock, so let's try to compare things again
if compare_old_state_to "${NEW_STATE}" ; then
	say "✅ the existing state is consistent with the desired state, will not re-deploy"
	exit 0
fi

# OK ... so if we've made it this far, the existing state and
# the incoming states are different ... let's reconcile

#
# 1) Identify the names of the existing configurations, and which collections are using them
#
CONF_PREFIX="__CONF_"
while IFS="/" read CONFIG COLLECTION ; do
	VAR="${CONF_PREFIX}${CONFIG}"
	if [ ! -v ${VAR} ] ; then
		# Declare the array to hold the collections
		eval "${VAR}=()"

		# Find the config's checksum in the stored state
		SUMVAR="${CONF_PREFIX}${CONFIG}_SUM"
		IFS="|" read NAME SUM DATE < <(grep "^${CONFIG}[|]" "${OLD_STATE}")
		eval "${SUMVAR}=${SUM@Q}"
	fi
	eval "${VAR}+=(${COLLECTION@Q})"
done < <(list_configs_with_collections)

#
# 2) Identify the names of the incoming configurations, and which collections are using them
#

#
# 3) Compare existing configurations with incoming configurations
#		3.1) If there's no name match, add the new configuration
#		3.2) If there's a name match, then compare the contents... if they match, leave
#			it alone and move on to the next configuration
#		3.3) If there's a name match but a contents mismatch, the old config
#			must be removed and replaced with the new one, but first all collections
#			that use it must also be removed
#
# 4) Create all new configurations (they'll be consumed by the incoming collections)
#
# 5) Compare existing collections with incoming collections
#		5.1) If there's no name match, add the new collection
#		5.2) If there's a name match, then compare the config names... if they match,
#			leave it alone and move on to the next collection
#		5.3) If there's a name match, but a config name mismatch, the old
#			collection must be removed
#
# 6) Create all new collections using the named configurations, which must already exist
#	since step 4
#
# 7) Rejoice, the state is synchronized!! Make note of it in Zookeeper "somehow", to
#	accelerate the process in the future, so that it's easy to avoid the full algorithm
#	if nothing has changed
#
