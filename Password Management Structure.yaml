Templates: |-
  // Render the name the configured secret/configMap for the given subsystem and value type
  //   - If a subsystem name is not given, the current subsystem's name will be used where appropriate
  //   - If a connection name is not given, then use the configured default, or "main" if none is set
  //   - If a type is not given, use the default type of either "conn", "cred-admin", or "cred-access"
  //     will be used, computed based on the template called (i.e. if the template has "conn", "admin",
  //     or "cred" in the name)
  arkcase.subsystem-access.name.conn(subsys?, conn?)
  arkcase.subsystem-access.name.admin(subsys?, conn?)
  arkcase.subsystem-access.name.cred(subsys?, conn?, type?)

  // Render only one envvar reference, including the secret/configMap name, saved into the given envVar name
  //   - If a subsystem name is not given, the current subsystem's name will be used where appropriate
  //   - If a connection name is not given, then use the configured default, or "main" if none is set
  //   - If a type is not given, use the default type of either "conn" or "cred-access" will be used, computed
  //     based on the template called (i.e. if the template has "conn" or "cred") in the name
  //   - The key will be referenced directly, and is the only required parameter
  //       - The key will have any mappings applied to it as necessary and stipulated in the configuration in order
  //         to arrive at the final key in the final object that the value is to be retrieved from
  //       - The key must be a valid configMap/secret key (i.e. ^[a-z0-9_.-]+$)
  //       - When analyzing the configuration, key mappings will also be validated against this regex
  //   - If the name is not given, generate it based on this pattern "arkcase_[${subsys}_]${type}_${key}"
  //       - If no subsystem name was expressly given, or it matches the local subsystem, then no subsys component will be added
  //       - The generated variable name will be all-uppercase by default
  //       - This also means that "local" envvars will have the "arkcase_" prefix regardless
  //   - If the name parameter is given, then...
  //       - The name parameter may also include these placeholders:
  //           ${subsys} == subsystem name (current or targeted)
  //           ${type} == extra information describing what the key is about (will never be empty)
  //           ${key} == the key itself, verbatim, with dots and dashes replaced with underscores
  //       - These value substitutions may have the suffix :u for uppercase, or :l for lowercase
  //       - Substituted values with no case specifier will be uppercased by default
  //       - The name parameter must be a valid BASH variable name (i.e. match /^[a-zA-Z0-9_]+$/)
  //   - If optional is not given, use the default value of "false" (boolean)
  //   - The target object kind will also depend on whether the object is expressly referenced, or if
  //     the template called had "conn" (configMap) or "cred" (secret) in the name. As ever, it must
  //     exist in the current namespace

  // Produce an env declaration for the specific value that reads from the source resource
  arkcase.subsystem-access.env.conn(subsys?, conn?, key, name?, optional?)
  arkcase.subsystem-access.env.admin(subsys?, conn?, key, name?, optional?)
  arkcase.subsystem-access.env.cred(subsys?, conn?, type?, key, name?, optional?)
  arkcase.subsystem-access.env.setting(subsys?, conn?, key, name?, optional?)

  // Produce a volumeMount entry for the specific value that links to the source resource
  arkcase.subsystem-access.volumeMount.conn(subsys?, conn?, key, mountPath?, optional?)
  arkcase.subsystem-access.volumeMount.admin(subsys?, conn?, key, mountPath?, optional?)
  arkcase.subsystem-access.volumeMount.cred(subsys?, conn?, key, type?, mountPath?, optional?)
  arkcase.subsystem-access.volumeMount.setting(subsys?, conn?, key, mountPath?, optional?)

  // Produce a volume entry for the specific value that mounts the source resource
  arkcase.subsystem-access.volume.conn(subsys?, conn?)
  arkcase.subsystem-access.volume.admin(subsys?, conn?)
  arkcase.subsystem-access.volume.cred(subsys?, conn?, type?)
  arkcase.subsystem-access.volume.setting(subsys?, conn?)

  - Envvar names will be uppercased unless expressly defined to not be by way of the name parameter, regardless
    of what the source secret/configMap YAML has defined

  - CamelCase is acceptable in key names (the name must be specified directly), but generally discouraged


  // Produce the full configuration for the subsystem - useful for quick analysis
  arkcase.subsystem-access.conf(subsys?)
  arkcase.subsystem.conf(subsys?)

  // Produce the name of the resource ... should only be used to render said resource
  arkcase.subsystem-access.name.conn(subsys?, conn?)
  arkcase.subsystem-access.name.admin(subsys?, conn?)
  arkcase.subsystem-access.name.cred(subsys?, conn?, type?)

  - Example default resource names (all secrets by default)
    ${release}-${subsys}-${conn}-conn // the connection information
    ${release}-${subsys}-${conn}-cred-admin // the admin credentials for this connection
    ${release}-${subsys}-${conn}-cred-access // the access credentials for this connection
    ${release}-${subsys}-${conn}-cred-access-${account} // account credentials for this connection
    ${release}-${subsys}-${conn}-cred-schema-${account} // account credentials for Database schema access for this connection

# The "mappings" entry is so we can support secrets with keys
# different to our own.  The ${myKeyX} names are known key names
# supported by the subsystem, while the ${targetKeyX} values are
# the keys in the target entity that actually house those values
#
# These mappings will be handled when rendering the environment
# variable mappings and whatnot to interact with the subsystem,
# and should be totally transparent to the chart developer.
#
# Deployers do need to specify these mappings when needed (i.e.
# to interact with RDS resources and whatnot). They may also
# have to provide the secrets/configmaps with those settings
# applied manually if they're not being rendered.

global:
  conf:
    acme:
      settings:
        # TODO: Plan out cert-manager support, since we'll need
        #         - a certificate for each pod that works for them individually,
        #           but also any service they share
        #             - Render keystores with these as needed
        #             - Render HAProxy certs with these as needed
        #         - the trust-manager ca.pem and cacerts to be trusted
        #         - Will need to be able to specify the issuer, possibly per-subsystem?
        # dialect: (default|cert-manager)
        # ...
        # Other various settings

      # The "connection:" item describes where the connection
      # information is stored. By default, it'll be in a generated configMap,
      # but can also be provided in other secrets for external services
      connection:
        default: main

        main:
          # Only one of secret: or configmap: are allowed
          secret: ${secretName}
          configMap: ${configMapName}
          mapped-keys:
            mapKey1: targetKey1
            mapKey2: targetKey2
            # ...

          # The "credentials:" item describes where the credentials
          # information is stored for different uses. By default
          # they will be stored in generated secrets, and most likely
          # may also include the connectivity information (i.e. host,
          # port, protocol, etc.)
          credentials:

            # Short form (i.e. no mappings, for briefer syntax):
            # access: ${secretName}
            access:
              secret: ${secretName}
              mapped-keys: ...

    ldap:
      settings:
        # other various non-connectivity settings

      connection:
        # The default connection to use if no connection name
        # is requested
        default: arkcase
        arkcase:
          # Only one of secret: or configMap: are allowed
          secret: ${secretName}
          configMap: ${configMapName}
          mapped-keys: ...

          credentials:
            # Abbreviated version:   admin: ${secretName}
            admin:
              secret: ${secretName}
              mapped-keys: ...

            # Abbreviated version:   access: ${secretName}
            access:
              secret: ${secretName}
              mapped-keys: ...

        foiaportal:
          # Only one of secret: or configMap: are allowed
          secret: ${secretName}
          configMap: ${configMapName}
          mapped-keys: ...

          credentials:
            # Abbreviated version:   admin: ${secretName}
            admin:
              secret: ${secretName}
              mapped-keys: ...

            # Abbreviated version:   access: ${secretName}
            access:
              secret: ${secretName}
              mapped-keys: ...

    reports:
      settings:
        # other various non-connectivity settings

      connection:
        # Only one of secret: or configMap: are allowed
        secret: ${secretName}
        configMap: ${configMapName}
        mapped-keys: ...

        credentials:
          admin:
            secret: ${secretName}
            mapped-keys: ...

          access:
            secret: ${secretName}
            mapped-keys: ...

    content:

      settings:
        # other various non-connectivity settings
        dialect: (s3|alfresco)

      connection:
        # Only one of secret: or configMap: are allowed
        secret: ${secretName}
        configMap: ${configMapName}
        mapped-keys: ...

        credentials:
          admin:
            secret: ${secretName}
            mapped-keys: ...

          access:
            secret: ${secretName}
            mapped-keys: ...

    messaging:
      settings:
        # other various non-connectivity settings

      # DEFAULT CONFIGMAP: ${release}-messaging-conn
      connection:
        # Only one of secret: or configMap: are allowed
        secret: ${secretName}
        configMap: ${configMapName}
        mapped-keys: ...

        credentials:
          admin:
            secret: ${secretName}
            mapped-keys: ...

          arkcase:
            secret: ${secretName}
            mapped-keys: ...

          cloudconfig:
            secret: ${secretName}
            mapped-keys: ...

          experimental:
            secret: ${secretName}
            mapped-keys: ...

    rdbms:
      settings:
        # other various non-connectivity settings
        dialect: (mysql|psql|oracle|mssql|db2|...)
        cloud: none|aws|azure|gke

      # DEFAULT CONFIGMAP: ${release}-rdbms-conn
      connection:
        # Only one of secret: or configMap: is allowed
        secret: ${secretName}
        configMap: ${configMapName}
        mapped-keys: ...

        credentials:
          # Abbreviated version:   admin: ${secretName}
          # DEFAULT SECRET: ${release}-rdbms-admin
          admin:
            secret: ${secretName}
            mapped-keys: ...

          # DEFAULT SECRET: ${release}-rdbms-schema-${schemaName}
          schema:
            # Abbreviated version:   arkcase: ${secretName}
            arkcase:
              secret: ${secretName}
              mapped-keys: ...

            # Abbreviated version:   pentaho: ${secretName}
            pentaho:
              secret: ${secretName}
              mapped-keys: ...


---

#
# This is an example secret from an RDS installation
#
apiVersion: v1
kind: Secret
metadata:
  name: rds-secret-example
type: Opaque
data:
  endpoint: dGVzdDEtcmRzLmNsaGV2dnlyOGlwaC51cy1lYXN0LTEucmRzLmFtYXpvbmF3cy5jb20=
  port: MzMwNg==
  password: UE1lZ0FXTVNlZW50RllLdlE0UEZnQWEzelF1
  username: YWRtaW4=

#
# This is an example configuration for the admin integration for that secret
#
global:
  conf:
    rdbms:
      settings:
        # other various non-connectivity settings
        dialect: (mysql|psql|oracle|mssql|db2|...)
        cloud: none|aws|azure|gke

      # DEFAULT CONFIGMAP: ${release}-rdbms-conn
      connection:
        # Only one of secret: or configMap: is allowed
        secret: rds-secret-example
        mapped-keys:
          # The "hostname" key would map to the "endpoint" key
          hostname: endpoint

---
# standard-connectivity-configurations:
global:
  conf:
    acme:
      settings:
        dialect: step-ca|acme|cert-manager
        # Possibly more settings? Maybe the issuer name for CM, etc?
      connection:
        url: ...
        credentials:
          admin:
            password: ...

    analytics:

    content:
      settings:
        dialect: s3|alfresco
        # Possibly more settings? Like Alfresco noindex, etc?
      connection:
        url: ...
        ui: ...
        credentials:
          admin:
            username:
            password:
          ro:
            username:
            password:
          rw:
            username:
            password:

    ldap:
      connection:
        tree-1:
          url: ...
          domain: ...
          realm: ...
          baseDn: ...
          groupsBaseDn: ...
          groupsFilter: ...
          groupsClass: ...
          groupsMemberAtt: ...
          groupsNameAtt: ...
          usersBaseDn: ...
          usersFilter: ...
          usersClass: ...
          usersNameAtt: ...
          usersMemberAtt: ...
        
        tree-2:
          url: ...
          baseDn: ...
          domain: ...
          realm: ...
          groupsBaseDn: ...
          groupsFilter: ...
          groupsClass: ...
          groupsMemberAtt: ...
          groupsNameAtt: ...
          usersBaseDn: ...
          usersFilter: ...
          usersClass: ...
          usersNameAtt: ...
          usersMemberAtt: ...

          credentials:
            admin:
              username: ...
              samAccount: ...
              password: ...
            access:
              username: ...
              samAccount: ...
              password: ...

    messaging:
      connection:
        url: ...
        credentials:
          admin:
            username:
            password:
          access-arkcase:
            username:
            password:
          access-cloudconfig:
            username:
            password:
          access-experimental:
            username:
            password:

    rdbms:
      settings:
        dialect: mysql|psql|mssql|oracle|...
        # Possibly more settings?
        cloud: none|aws|azure|gke
      connection:
        host: ...
        port: ...
        credentials:
          admin:
            username:
            password:
          schema-arkcase:
            username:
            password:
            realname:
          schema-pentaho:
            username:
            password:
            realname:
          schema-pentaho-jcr:
            username:
            password:
            realname:
          schema-pentaho-quartz:
            username:
            password:
            realname:

    reports:
      connection:
        url: ...
        credentials:
          admin:
            username:
            password:
          access:
            username:
            password:

    search:
      connection:
        url: ...
        # Not necessary yet
        credentials:
          admin:
            username:
            password:
          access:
            username:
            password:

    zookeeper:
      connection:
        hosts: ...
        # Not necessary yet
        credentials:
          admin:
            username:
            password:
          access:
            username:
            password:

---


acme:
  status: complete
  owned:
    accounts:
      - admin

messaging:
  status: complete
  owned:
    accounts:
      - admin
      - arkcase
      - cloudconfig
      - experimental

content-minio:
  status: complete
  owned:
    accounts:
      - minio-admin
      - minio-ro
      - minio-rw

    # Only applicable for RW/RO users
    commands:
      - mcli admin user add local "${username}" "${password}"
      # Policy can be "readonly" or "readwrite"
      - mcli admin policy attach local "${policy}" --user "${username}"

reports:
  status: No work done yet
  owned:
    accounts:
      # This password must be updated using REST, and using the pentaho-admin user,
      # which will already have been reset b/c of the dependency on LDAP being online,
      # which will only come online after doing all the password-fu
      #
      # Possibly with:
      #   curl -vL
      #     --header "Content-Type: application/json"
      #     --request "PUT"
      #     --disallow-username-in-url
      #     --data '{ "userName" : "${username}", "password" : "${password}" }'
      #     --config <(echo -n '--user ${adminUsername}:${adminPassword}')
      #     https://localhost:8443/pentaho/api/userroledao/updatePassword
      - admin
  ldap:
    accounts:
      - pentaho-access
      - pentaho-admin

ldap:
  status: No work done yet
  owned:
    accounts:
      - admin
      - access
    commands:
      - &samba samba-tool user setpassword "${username}" --newpassword="${password}"
  subsystems:
    accounts:
      - alfresco-admin
      - alfrseco-ro
      - alfresco-rw
      - pentaho-admin
      - pentaho-access
      - arkcase-admin
    commands:
      - &samba samba-tool user setpassword "${username}" --newpassword="${password}" 

rdbms:
  status: No work done yet
  owned:
    accounts:
      - admin
      - ${schemata}
    commands:
      mysql: ALTER USER '${username}'@'%' IDENTIFIED BY '${password}'; FLUSH PRIVILEGES;
      mariadb: ALTER USER '${username}'@'%' IDENTIFIED BY '${password}'; FLUSH PRIVILEGES;
      psql: ALTER USER '${username}' SET PASSWORD TO '${password}'; FLUSH PRIVILEGES;
    notes: |
      - On first boot must:
          - rename legacy schemata to modern names (not possible in MySQL? https://stackoverflow.com/a/2298602/684350)
          - rename legacy usernames to modern names
          - THEN proceed with the normal boot
  # i.e. these passwords are defined elsewhere
  external:
    alfresco:
      admin:
        commands:
          - |
            --
            -- capture string_value as ${encodingType}
            --
            SELECT anp1.node_id, anp1.qname_id, anp1.string_value
            FROM alf_node_properties anp1
                INNER JOIN alf_qname aq1 ON aq1.id = anp1.qname_id
                INNER JOIN alf_node_properties anp2 ON anp2.node_id = anp1.node_id
                INNER JOIN alf_qname aq2 ON aq2.id = anp2.qname_id
            WHERE aq1.local_name = 'hashIndicator'
            AND aq2.local_name = 'username'
            AND anp2.string_value = 'admin';
          - |
            --
            -- capture node_id as ${nodeId}, qname_id as ${qnameId}
            --
            SELECT anp1.node_id, anp1.qname_id, anp1.string_value
            FROM alf_node_properties anp1
                INNER JOIN alf_qname aq1 ON aq1.id = anp1.qname_id
                INNER JOIN alf_node_properties anp2 ON anp2.node_id = anp1.node_id
                INNER JOIN alf_qname aq2 ON aq2.id = anp2.qname_id
            WHERE aq1.local_name = 'passwordHash'
            AND aq2.local_name = 'username'
            AND anp2.string_value = 'admin';
          - |
            --
            -- encodedPassword = encodePassword(${encodingType}, ${password})
            --
            -- There are 3 command-line scripts available that produce the correct value, each
            -- named after the ${encodingType}, such that one can do something like:
            --
            --   encodedPassword="$(echo -n "${password}" | "${encodingType}")"
            --
            -- and then consume that value in the update.
            UPDATE alf_node_properties
              SET string_value = '${encodedPassword}'
            WHERE node_id = ${nodeId} AND qname_id = ${qnameId};

content-alfresco:
  status: No work done yet
  owned:
    accounts:
      # This password will be updated by the RDBMS system's bootup,
      # unless the RDBMS system is external (i.e. RDS, etc...)
      - admin
  ldap:
    accounts:
      - alfresco-admin
      - alfresco-access
  notes:
    - |
      Create an executable that connects to the DB and does it for us as part of
      Alfresco's initialization (i.e. an init container)

      - /usr/local/bin/reset-admin-password dbType host[:port] username password-env-or-file [instance/][schema@]dbName

      - Reference: https://docs.alfresco.com/content-services/7.3/admin/security/#adminpwddefaultauth

      - Maybe create an AMP that does this as one of the initial bootup steps?

            --
            -- capture string_value as ${encodingType}
            --
            SELECT anp1.node_id, anp1.qname_id, anp1.string_value
            FROM alf_node_properties anp1
                INNER JOIN alf_qname aq1 ON aq1.id = anp1.qname_id
                INNER JOIN alf_node_properties anp2 ON anp2.node_id = anp1.node_id
                INNER JOIN alf_qname aq2 ON aq2.id = anp2.qname_id
            WHERE aq1.local_name = 'hashIndicator'
            AND aq2.local_name = 'username'
            AND anp2.string_value = 'admin';

            --
            -- capture node_id as ${nodeId}, qname_id as ${qnameId}
            --
            SELECT anp1.node_id, anp1.qname_id, anp1.string_value
            FROM alf_node_properties anp1
                INNER JOIN alf_qname aq1 ON aq1.id = anp1.qname_id
                INNER JOIN alf_node_properties anp2 ON anp2.node_id = anp1.node_id
                INNER JOIN alf_qname aq2 ON aq2.id = anp2.qname_id
            WHERE aq1.local_name = 'passwordHash'
            AND aq2.local_name = 'username'
            AND anp2.string_value = 'admin';

            --
            -- encodedPassword = encodePassword(${encodingType}, ${password})
            --
            -- There are 3 command-line scripts available that produce the correct value, each
            -- named after the ${encodingType}, such that one can do something like:
            --
            --   encodedPassword="$(echo -n "${password}" | "${encodingType}")"
            --
            -- and then consume that value in the update.
            UPDATE alf_node_properties
              SET string_value = '${encodedPassword}'
            WHERE node_id = ${nodeId} AND qname_id = ${qnameId};
